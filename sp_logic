import logging
import uuid
import mimetypes
from datetime import datetime
from typing import List, Dict, Any

from app.model.document_schema import DocumentModel, SharePointInfoModel, StepModel
from app.model.enums import StepName, StepStatus, StepResult, IngestionStatus
from app.services.blob_upload_service import BlobUploaderFactory

logger = logging.getLogger(__name__)

class SharePointIngestionService:
    """
    Service to ingest SharePoint documents into MongoDB with metadata.
    Also triggers Azure Blob upload based on configuration.
    """

    def __init__(self, db, client_id: str, client_secret: str):
        self.db = db
        self.client_id = client_id
        self.client_secret = client_secret
        self.run_management = self.db["run_management"]
        self.run_documents = self.db["run_documents"]
        self.sharepoint_logs = self.db["sharepoint_ingestion_logs"]

    def ingest(self, sp_client, tenant_id: str, engagement_id: str, year: str, quarter: str,
               request_id: str, use_case_name: str, is_open_source_pipeline: bool, document_upload: bool) -> Dict[str, Any]:
        """
        Main ingestion function to pull documents from SharePoint and insert into MongoDB.
        """
        try:
            run_doc = self._fetch_run_metadata(tenant_id, engagement_id, request_id)
            if not run_doc:
                return {"status": StepResult.FAILED, "message": "Run management not found"}

            run_id = run_doc["run_id"]
            matched_meta = self._get_metadata_for_quarter(run_doc, year, quarter, request_id)
            if not matched_meta:
                return {"status": StepResult.FAILED, "message": "Metadata not found"}

            all_docs, doc_run_ids = self._collect_documents(sp_client, matched_meta, request_id, run_id,
                                                            tenant_id, engagement_id, year, quarter,
                                                            use_case_name, is_open_source_pipeline)

            if all_docs:
                self.run_documents.insert_many(all_docs)
                self._mark_step_success(request_id, StepName.SHAREPOINT_INGESTION)
                self.sharepoint_logs.update_one(
                    {"request_id": request_id},
                    {"$set": {
                        "status": IngestionStatus.INGESTION_COMPLETE,
                        "doc_run_ids": list(set(doc_run_ids)),
                        "document_uploaded": True,
                        "total_new_files": len(all_docs),
                        "completed_at": datetime.utcnow().isoformat()
                    }}
                )
                return {"status": StepResult.SUCCESS, "message": "Ingestion completed successfully", "document_uploaded": True}

            self._mark_step_failed(request_id, StepName.SHAREPOINT_INGESTION, "No files to ingest")
            self.sharepoint_logs.update_one(
                {"request_id": request_id},
                {"$set": {
                    "status": IngestionStatus.NO_NEW_FILES,
                    "message": "No new files found to ingest",
                    "document_uploaded": False,
                    "completed_at": datetime.utcnow().isoformat()
                }}
            )
            return {"status": StepResult.FAILED, "message": "No new files found", "document_uploaded": False}

        except Exception as e:
            self._mark_step_failed(request_id, StepName.SHAREPOINT_INGESTION, str(e))
            return {"status": StepResult.FAILED, "message": str(e), "document_uploaded": False}

    def _fetch_run_metadata(self, tenant_id: str, engagement_id: str, request_id: str) -> Any:
        run_doc = self.run_management.find_one({"tenant_id": tenant_id, "engagement_id": engagement_id})
        if not run_doc:
            self._log_error(request_id, "Run management entry not found")
        return run_doc

    def _get_metadata_for_quarter(self, run_doc: Dict[str, Any], year: str, quarter: str, request_id: str) -> Any:
        matched_meta = next((m for m in run_doc.get("metadata", []) if m["year"] == int(year) and m["quarter"] == quarter), None)
        if not matched_meta:
            self._log_error(request_id, "No metadata for given year/quarter")
        return matched_meta

    def _collect_documents(self, sp_client, matched_meta: Dict[str, Any], request_id: str, run_id: str,
                           tenant_id: str, engagement_id: str, year: str, quarter: str,
                           use_case_name: str, is_open_source_pipeline: bool) -> (List[Dict[str, Any]], List[str]):
        all_docs = []
        seen_base64s = set()
        all_doc_run_ids = []
        year_quarter_path = matched_meta.get("year_quarter_path")

        for sub_product in matched_meta.get("sub_product_types", []):
            sub_product_type = sub_product["sub_product_type"]
            for obligor in sub_product["obligors"]:
                obligor_name = obligor["obligor_name"]
                doc_run_id = obligor["doc_run_id"]
                obligor_path = f"{year_quarter_path}/{sub_product_type}/{obligor_name}"

                try:
                    obligor_folder = sp_client.get_folder(obligor_path)
                    sp_client.ctx.load(obligor_folder.expand(["Folders", "Files"]))
                    sp_client.ctx.execute_query()

                    existing_docs = self.run_documents.find({"doc_run_id": doc_run_id, "base64": {"$exists": True}})
                    existing_base64s = set(doc["base64"] for doc in existing_docs)

                    files = sp_client.traverse_files(obligor_folder)

                    for file_obj in files:
                        base64_str = sp_client.get_base64_content(file_obj)
                        if not base64_str or base64_str in seen_base64s or base64_str in existing_base64s:
                            continue

                        seen_base64s.add(base64_str)
                        original_filename = file_obj.properties["Name"]
                        ext = original_filename.split(".")[-1].lower() if "." in original_filename else "unknown"

                        doc = DocumentModel(
                            request_id=request_id,
                            doc_run_id=doc_run_id,
                            run_id=run_id,
                            tenant_id=tenant_id,
                            engagement_id=engagement_id,
                            year=int(year),
                            quarter=quarter,
                            sub_product_type=sub_product_type,
                            obligor_name=obligor_name,
                            doc_id=str(uuid.uuid4()),
                            original_filename=original_filename,
                            base64=base64_str,
                            file_type=ext,
                            use_case_name=use_case_name,
                            is_open_source_pipeline=is_open_source_pipeline,
                            sharepoint_info=SharePointInfoModel(
                                relative_path=file_obj.properties["ServerRelativeUrl"],
                                library_name="Documents",
                                site_url=sp_client.site_url
                            ),
                            steps=[
                                StepModel(
                                    step_name=StepName.SHAREPOINT_INGESTION,
                                    result=StepResult.SUCCESS,
                                    status=StepStatus.COMPLETED,
                                    timestamp=datetime.utcnow().isoformat()
                                )
                            ]
                        )
                        all_docs.append(doc.dict())
                        all_doc_run_ids.append(doc_run_id)

                except Exception as e:
                    logger.exception(f"[ERROR] {obligor_path} failed: {e}")
                    continue

        return all_docs, list(set(all_doc_run_ids))

    def _mark_step_success(self, request_id: str, step: StepName):
        self.sharepoint_logs.update_one(
            {"request_id": request_id, "steps.step_name": step},
            {"$set": {
                "steps.$.status": StepStatus.COMPLETED,
                "steps.$.result": StepResult.SUCCESS,
                "steps.$.timestamp": datetime.utcnow().isoformat()
            }}
        )

    def _mark_step_failed(self, request_id: str, step: StepName, message: str):
        self.sharepoint_logs.update_one(
            {"request_id": request_id, "steps.step_name": step},
            {"$set": {
                "steps.$.status": StepStatus.FAILED,
                "steps.$.result": StepResult.FAILED,
                "steps.$.timestamp": datetime.utcnow().isoformat(),
                "steps.$.message": message
            }}
        )

    def _log_error(self, request_id: str, message: str):
        self.sharepoint_logs.update_one(
            {"request_id": request_id},
            {"$set": {
                "status": IngestionStatus.ERROR,
                "message": message,
                "completed_at": datetime.utcnow().isoformat()
            }}
        )
        logger.error(f"[INGEST ERROR] {message}")
