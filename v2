from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any, List
from datetime import datetime
import logging

from app.enums import StepName, StepStatus, StepResult
from app.services.document_vectorization_service import DocumentVectorizationService

logger = logging.getLogger(__name__)

class VectorizationService:
    def __init__(self, run_documents_collection, request_logs_collection, max_workers: int = 4):
        self.run_documents_collection = run_documents_collection
        self.request_logs_collection = request_logs_collection
        self.doc_vectorizer = DocumentVectorizationService()
        self.max_workers = max_workers

    def run_for_request_id(self, request_id: str):
        """
        Run vectorization in parallel for all documents under the given request_id.
        Only processes documents with successful TEXT_EXTRACTION.
        """
        logger.info(f"[Vectorization] Starting vectorization for request_id={request_id}")

        try:
            documents = list(self.run_documents_collection.find({"request_id": request_id}))
            if not documents:
                msg = f"No documents found for request_id={request_id}"
                logger.warning(f"[Vectorization] {msg}")
                self._update_overall_status(request_id, StepResult.SKIPPED, msg)
                return

            skipped = processed = failed = 0
            futures = {}
            docs_to_vectorize = []

            for doc in documents:
                if self._is_text_extracted_successfully(doc):
                    docs_to_vectorize.append(doc)
                else:
                    skipped += 1
                    self._update_doc_step(doc["_id"], StepResult.SKIPPED, "TEXT_EXTRACTION not successful, skipping vectorization")

            if not docs_to_vectorize:
                msg = f"No documents qualified for vectorization under request_id={request_id}"
                logger.warning(f"[Vectorization] {msg}")
                self._update_overall_status(request_id, StepResult.SKIPPED, msg)
                return

            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                for doc in docs_to_vectorize:
                    try:
                        payload = self._prepare_payload(doc)
                        future = executor.submit(self._process_single_document, doc["_id"], payload)
                        futures[future] = doc["_id"]
                    except ValueError as ve:
                        skipped += 1
                        logger.warning(f"[Vectorization] Payload preparation failed for doc_id={doc.get('doc_id')}: {ve}")
                        self._update_doc_step(doc["_id"], StepResult.SKIPPED, str(ve))

                for future in as_completed(futures):
                    doc_id = futures[future]
                    try:
                        result = future.result()
                        if result == "FAILED":
                            failed += 1
                            logger.error(f"[Vectorization] Failed to process doc_id={doc_id}")
                        else:
                            processed += 1
                            logger.info(f"[Vectorization] Successfully processed doc_id={doc_id}")
                    except Exception as e:
                        failed += 1
                        logger.error(f"[Vectorization] Unexpected error during processing doc_id={doc_id}: {str(e)}")
                        self._update_doc_step(doc_id, StepResult.FAILED, str(e))

            msg = f"Vectorization completed: Processed={processed}, Skipped={skipped}, Failed={failed}"
            logger.info(f"[Vectorization] {msg}")
            overall_status = StepResult.SUCCESS if processed > 0 and failed == 0 else StepResult.FAILED
            self._update_overall_status(request_id, overall_status, msg)

        except Exception as e:
            logger.exception(f"[Vectorization] Fatal error during vectorization for request_id={request_id}: {str(e)}")
            self._update_overall_status(request_id, StepResult.FAILED, str(e))

    def _prepare_payload(self, doc: Dict[str, Any]) -> Dict[str, Any]:
        """
        Prepare and validate vectorization payload for a document.
        Raises ValueError if required fields are missing.
        """
        required_fields = ["doc_run_id", "doc_id", "sas_url"]
        meta_fields = ["tenant_id", "engagement_id", "sub_product_type", "obligor_name", "year", "quarter"]

        for field in required_fields:
            if not doc.get(field):
                raise ValueError(f"Missing required field: {field}")
        for field in meta_fields:
            if not doc.get(field):
                raise ValueError(f"Missing meta field: {field}")

        return {
            "doc_run_id": doc["doc_run_id"],
            "doc_id": doc["doc_id"],
            "sas_url": doc["sas_url"],
            "use_case_name": doc.get("use_case_name", "Loan File Review"),
            "is_open_source_pipeline": doc.get("is_open_source_pipeline", False),
            "doc_file_type": doc.get("doc_file_type", "pdf"),
            "meta": {
                "tenant_id": doc["tenant_id"],
                "engagement_id": doc["engagement_id"],
                "sub_product_type": doc["sub_product_type"],
                "obligor_name": doc["obligor_name"],
                "year": doc["year"],
                "quarter": doc["quarter"],
                "is_tape_file": doc.get("is_tape_file", False)
            }
        }

    def _process_single_document(self, mongo_id, payload: Dict[str, Any]) -> str:
        try:
            logger.info(f"[Vectorization] Running vectorization for doc_id={payload['doc_id']}")
            result_payload = self.doc_vectorizer.run_vectorization(payload)

            if not result_payload or not isinstance(result_payload, dict):
                self._update_doc_step(mongo_id, StepResult.FAILED, "No output from vectorization", payload=None)
                return "FAILED"

            status = result_payload.get("status", "FAILED").strip().upper()
            message = result_payload.get("messages", "No message returned")
            step_result = StepResult.SUCCESS if status == "SUCCESS" else StepResult.FAILED
            self._update_doc_step(mongo_id, step_result, message, result_payload)
            return "SUCCESS" if step_result == StepResult.SUCCESS else "FAILED"

        except Exception as e:
            logger.exception(f"[Vectorization] Exception while processing doc_id={payload.get('doc_id')}: {str(e)}")
            self._update_doc_step(mongo_id, StepResult.FAILED, str(e))
            return "FAILED"

    def _update_doc_step(self, mongo_id, step_result: str, message: str, payload: Dict[str, Any] = None):
        step_status = StepStatus.COMPLETED if step_result == StepResult.SUCCESS else StepStatus.FAILED
        update_obj = {
            "steps.$[step].result": step_result,
            "steps.$[step].status": step_status,
            "steps.$[step].timestamp": datetime.utcnow().isoformat(),
            "steps.$[step].message": message
        }
        if payload:
            update_obj["steps.$[step].response_payload"] = payload

        result = self.run_documents_collection.update_one(
            {"_id": mongo_id},
            {"$set": update_obj},
            array_filters=[{"step.step_name": StepName.VECTOR_INDEXING}]
        )

        if result.modified_count == 0:
            insert_step = {
                "step_name": StepName.VECTOR_INDEXING,
                "result": step_result,
                "status": step_status,
                "timestamp": datetime.utcnow().isoformat(),
                "message": message
            }
            if payload:
                insert_step["response_payload"] = payload

            self.run_documents_collection.update_one(
                {"_id": mongo_id},
                {"$push": {"steps": insert_step}}
            )

    def _update_overall_status(self, request_id: str, step_result: str, message: str):
        step_status = StepStatus.COMPLETED if step_result == StepResult.SUCCESS else StepStatus.FAILED
        update_obj = {
            "steps.$[step].result": step_result,
            "steps.$[step].status": step_status,
            "steps.$[step].timestamp": datetime.utcnow().isoformat(),
            "steps.$[step].message": message
        }
        result = self.request_logs_collection.update_one(
            {"request_id": request_id},
            {"$set": update_obj},
            array_filters=[{"step.step_name": StepName.VECTOR_INDEXING}]
        )

        if result.modified_count == 0:
            insert_step = {
                "step_name": StepName.VECTOR_INDEXING,
                "result": step_result,
                "status": step_status,
                "timestamp": datetime.utcnow().isoformat(),
                "message": message
            }
            self.request_logs_collection.update_one(
                {"request_id": request_id},
                {"$push": {"steps": insert_step}}
            )

    def _is_text_extracted_successfully(self, doc: Dict[str, Any]) -> bool:
        for step in doc.get("steps", []):
            if step.get("step_name") == StepName.TEXT_EXTRACTION and step.get("result") == StepResult.SUCCESS:
                return True
        return False
